import hashlib
import torch
import fastrand
import math
import numba
import numpy as np
import time
import os
from flask import Flask, request, jsonify

PORT = int(os.getenv("PORT", 12121))

app = Flask(__name__)

# Global state (demo only!)
A = None
B = None
C = None
leaves = None       # row-hashes of C
merkle_tree = None
commitment_root = None
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# create timer decorator
def timer(func):
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        end = time.time()
        print(f"{func.__name__} took {end - start} seconds")
        return result
    return wrapper

def create_rowhashes(n, master_seed):
    row_hashes = []
    current_seed = master_seed
    for _ in range(n):
        row_hashes.append(sha256_bytes(current_seed))
        current_seed = sha256_bytes(current_seed)
    return row_hashes, current_seed

def create_row_from_hash(n, seed):
    s0 = seed & 0xFFFFFFFFFFFFFFF
    s1 = int(seed >> 64) & 0xFFFFFFFFFFFFFFF
    out, _, _ = xorshift128plus_array(n, s0, s1)
    torch_64_max = float(1 << 64)
    return torch.tensor(out, dtype=torch.float64) / torch_64_max

@timer
def create_deterministic_rowhash_matrix(n, master_seed):
    row_hashes, next_hash = create_rowhashes(n, master_seed)
    rows = []
    for i in range(n):
        row_data = create_row_from_hash(n, int.from_bytes(row_hashes[i], "big"))
        rows.append(row_data)
    return torch.stack(rows), next_hash

@numba.njit
def xorshift128plus_array(n, s0, s1):
    # Generate n samples. s0, s1 are 64-bit seeds.
    out = np.empty(n, dtype=np.uint64)
    for i in range(n):
        # Xorshift128+ example
        x = s0
        y = s1
        s0 = y
        x ^= x << 23
        s1 = x ^ y ^ (x >> 17) ^ (y >> 26)
        out[i] = (s1 + y) & ((1 << 64) - 1)
    return out, s0, s1

def pcg_uniform_torch64(count, seed0, seed1):
    arr_int, seed0, seed1 = xorshift128plus_array(count, seed0, seed1)
    arr_float = arr_int.astype(np.float64) / (1 << 64)
    return torch.from_numpy(arr_float)

def set_seeds(seed: int):
    seed1 = seed & 0xFFFFFFFF
    seed2 = seed >> 32 & 0xFFFFFFFF
    fastrand.xorshift128plus_seed1(seed1)
    fastrand.xorshift128plus_seed2(seed2)

@timer
def pcg_uniform_torch64(count: int) -> torch.Tensor:
    """
    Returns a double precision tensor of length 'count',
    each entry in [0, 1), derived from 64-bit PCG output.
    """
    print("Generating", count, "uniform samples...")
    out = torch.empty(count, dtype=torch.float64)
    two_64 = float(1 << 64)
    for i in range(count):
        out[i] = fastrand.xorshift128plus() / two_64
    return out

@timer
def pcg_randn64(shape) -> torch.Tensor:
    """
    Returns a double precision (float64) PyTorch tensor of shape 'shape',
    filled with standard normal samples generated by the above PCG64-like RNG.
    Uses Box–Muller in a vectorized manner.
    """
    # Number of total samples needed
    numel = 1
    for s in shape:
        numel *= s

    # We need pairs for Box–Muller (two normal samples per pair).
    half = (numel + 1) // 2

    # Generate 2*half uniform [0,1) values
    u = pcg_uniform_torch64(2 * half)  # [u1(0), u1(1), ..., u1(half-1), u2(0), ..., u2(half-1)]
    u1 = u[:half]
    u2 = u[half:]

    # Box–Muller transform: r = sqrt(-2 ln(u1)), theta = 2πu2
    r = (-2.0 * u1.log()).sqrt_()
    theta = 2.0 * math.pi * u2

    # Allocate an output tensor for the final normal values
    z = torch.empty(2 * half, dtype=torch.float64)
    z[:half] = r * theta.cos()
    z[half:] = r * theta.sin()

    # If numel is odd, truncate the last extra sample
    z = z[:numel]

    return z.reshape(shape)

#################################################################
# Merkle Tree Construction
#################################################################
def sha256_bytes(data: bytes) -> bytes:
    return hashlib.sha256(data).digest()

def merkle_build_tree(leaves: list[bytes]) -> list[bytes]:
    # Build from bottom up, store all levels in an array, root at index 0.
    level = leaves[:]
    tree = []
    while len(level) > 1:
        next_level = []
        for i in range(0, len(level), 2):
            left = level[i]
            if i+1 < len(level):
                right = level[i+1]
            else:
                right = left
            combined = sha256_bytes(left + right)
            next_level.append(combined)
        tree.extend(level)
        level = next_level
    tree.extend(level)
    tree.reverse()
    return tree

def merkle_find_root(tree: list[bytes]) -> bytes:
    return tree[0] if tree else b''

#################################################################
# Flask Endpoints
#################################################################

@app.route("/setAB", methods=["POST"])
def setAB():
    """
    Receive A, B in JSON form (small toy example).
    Compute C = A x B on GPU. Build a Merkle tree of row hashes for C.
    """
    global A, B, C, leaves, merkle_tree, commitment_root

    data = request.json
    n = data["n"]  # shape (n, n)
    master_seed = data["seed"]  # shape (n, n)
    master_seed = bytes.fromhex(master_seed)

    A, next_seed = create_deterministic_rowhash_matrix(n, master_seed)
    B, _ = create_deterministic_rowhash_matrix(n, next_seed)


    # Compute C
    C_t = torch.matmul(A, B)
    C = C_t.cpu()  # Store on CPU for hashing

    # Build Merkle over row-hashes
    leaves_temp = []
    for i in range(C.shape[0]):
        row_bytes = C[i,:].numpy().tobytes()
        leaves_temp.append(sha256_bytes(row_bytes))
    tree = merkle_build_tree(leaves_temp)
    root = merkle_find_root(tree)

    leaves = leaves_temp
    merkle_tree = tree
    commitment_root = root

    return jsonify({"status": "ok"})

@app.route("/getCommitment", methods=["GET"])
def getCommitment():
    """
    Return the Merkle root (commitment to C).
    """
    global commitment_root
    return jsonify({"commitment_root": commitment_root.hex()})

@app.route("/computeCR", methods=["POST"])
def computeCR():
    """
    Receive a challenge vector r, return C @ r.
    """
    global C
    data = request.json
    r_list = data["r"]  # shape (n)
    r_t = torch.tensor(r_list, dtype=torch.float64, device=device)

    C_t = C.to(device)
    Cr_t = torch.matmul(C_t, r_t)
    Cr = Cr_t.cpu().tolist()
    return jsonify({"Cr": Cr})

def merkle_proof_path(idx: int, leaves_list: list[bytes], tree: list[bytes]) -> list[str]:
    """
    Return the Merkle authentication path for a given leaf index
    (naive approach: re-build partial trees and gather sibling hashes).
    Return as list of hex strings for easy JSON transport.
    """
    path = []
    level = leaves_list[:]
    current_idx = idx
    while len(level) > 1:
        next_level = []
        for i in range(0, len(level), 2):
            left = level[i]
            right = level[i+1] if (i+1 < len(level)) else left
            combined = sha256_bytes(left + right)
            next_level.append(combined)

        sibling_idx = current_idx ^ 1  # flip last bit
        if sibling_idx < len(level):
            path.append(level[sibling_idx].hex())

        current_idx //= 2
        level = next_level
    return path

@app.route("/getRowProof", methods=["POST"])
def getRowProof():
    """
    Receive a row index, return:
      - row data (list of floats)
      - merkle path
    """
    global C, leaves, merkle_tree
    data = request.json
    row_idx = data["row_idx"]
    row_data = C[row_idx, :].tolist()

    # Build proof
    proof = merkle_proof_path(row_idx, leaves, merkle_tree)

    return jsonify({"row_data": row_data, "merkle_path": proof})
@app.route("/getRowProofs", methods=["POST"])
def getRowProofs():
    """
    Receives a list of row indexes. Returns an object with:
    {
      "rows": [
        {
          "row_idx": <int>,
          "row_data": [float, ...],
          "merkle_path": [str, ...]
        },
        ...
      ]
    }
    """
    global C, leaves, merkle_tree

    data = request.json
    row_idxs = data["row_idxs"]

    rows_output = []
    for row_idx in row_idxs:
        # Extract row data
        row_data = C[row_idx, :].tolist()
        # Build Merkle proof for this row
        path = merkle_proof_path(row_idx, leaves, merkle_tree)

        rows_output.append({
            "row_idx": row_idx,
            "row_data": row_data,
            "merkle_path": path
        })

    return jsonify({"rows": rows_output})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=PORT, debug=False)
